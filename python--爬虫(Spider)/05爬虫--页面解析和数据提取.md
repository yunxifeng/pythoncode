# 页面解析和数据提取
- 数据分类
    - 结构化数据: 先有结构,再谈数据
            - JSON文件
                - JSON Path工具
                - 转化成Python类型(json.loads(json_data))
            - XML文件
                - 转换成Python类型(xmltodict)
                - Xpath
                - CSS选择器
                - 正则
    - 非结构化数据: 先有数据,再谈结构
            - 文本
            - 电话号码
            - 邮箱地址
                - 正则
            - HTML文件
                - 正则,Xpath,CSS选择器
- 几个常用提取信息工具的比较：
    - 正则： 很快，不好用，无需安装
    - beautifulsoup4：慢，使用简单，安装简单
    - lxml： 比较快，使用简单，安装一般
## 正则表达式
- 一套规则,可以在字符串文本中进行搜查替换
- 正则的基本使用
    - 案例: 05--p01.py
- 正则常用方法:
    - match: 从开始位置开始查找,一次匹配,找到一个就退出
        - 案例: 05--p02.py 
    - search: 从任何位置查找,一次匹配,找到一个就退出
        - 案例: 05--p03.py
    - findall: 全部匹配,找出所有符合的结果,返回列表list
        - 案例: 05--p03.py
    - finditer: 全部匹配,返回迭代器
        - 案例: 05--p03.py
    - split: 分割字符串,返回列表list
    - sub: 替换
- 匹配中文
    - 中文unicode范围[主要]在[u4e00-u9fa5],并不是所有中文都是unicode编码
    - 案例: 05--p04.py
- 贪婪与非贪婪 
    - 贪婪模式: 在整个表达式匹配成功的前提下,尽可能多的匹配
    - 非贪婪模式: 在整个表达式匹配成功的前提下,尽可能少的匹配
    - python中数量词默认是贪婪模式
    - 例:
        - 查找文本abbbbbcccc
        - re是ab*    # *: 表示前面的内容重复零次或者多次
        - 贪婪模式: 匹配结果: abbbbb
        - 非贪婪模式: 匹配结果: a
## XML文件
- XML(Extensible Markup Language):可扩展标记语言
- 参考资料: [http://www.w3school.com.cn/xml/index.asp]
- 概念: 父节点, 子节点, 先辈节点, 兄弟节点, 后辈节点
- 案例: 05--p05.xml
## XPath
- XPath(XML Path Language)
- 是一门在XML文档中查找信息的语言
- 官方文档：[http://www.w3school.com.cn/xpath/index.asp]
- XPath开发工具
    - 开元的XPath表达式工具： XMLQuire
    - chrome插件： Xpath Helper
    - Firefox插件： XPath Checker  
- 常用路径表达式：
    - nodename : 选取此节点的所有子节点
    - / : 从根节点开始选
    - //: 选取元素，而不考虑元素的具体位置
    - . :  当前节点
    - ..:父节点
    - @： 选取属性
    - 案例：
        - booksotre: 选取bookstore下的所有子节点
        - /booksotre: 选取根元素
        - booksotre/book: 选取bookstore的所有为book的子元素
        - //book: 选取book子元素
        - //@lang: 选取属性名称为lang的所有节点
- 谓语(Predicates)
    - 谓语用来查找某个特定的节点，被向前在方括号中
    - /bookstore/book[1]: 选取第一个属于bookstore下叫book的元素
    - /bookstore/book[last()]: 选取最后一个属于bookstore下叫book的元素
    - /bookstore/book[last()-1]: 选取倒数第二个属于bookstore下叫book的元素
    - /bookstore/book[position()<3]: 选取属于bookstore下叫book的前两个元素
    - /bookstore/book[@lang]: 选取属于bookstore下叫book的,含有属性lang元素
    - /bookstore/book[@lang="cn"]: 选取属于bookstore下叫book的,含有属性lang的值是cn的元素
    - /bookstore/book[@price < 90]: 选取属于bookstore下叫book的,含有属性price的，且值小于90的元素
    - /bookstore/book[@price < 90]/title: 选取属于bookstore下叫book的,含有属性price的，且值小于90的元素的子元素title    
- 通配符
    - * : 任何元素节点
    - @*： 匹配任何属性节点
    - node(): 匹配任何类型的节点
- 选取多个路径
    - //book/tile  | //book/author : 选取book元素中的title和author元素
    - //tile | //price: 选取文档中所有的title和price元素 
## lxml库
- python的HTML/XML的解析器, 用于提取数据
- 官方文档：[http://lxml.de/index.html]
- 安装lxml包: conda install lxml
- 功能：
    - 解析HTML-->html = etree.HTML(*)
        - 案例: 05--p06.py
    - XML文件读取-->html = etree.parse("./05--p05.xml")
        - 案例: 05--p06.py, 05--p05.html
    - etree和XPath的配合使用
        - 案例: 05--p06.py
## CSS选择器--BeautifulSoup4
- 安装: conda install BeautifulSoup4
- 官方文档: [http://beautifulsoup.readthedocs.io/zh_CN/v4.4.0/]
- 案例: 05--p07.py
- 四大对象:
    - Tag
    - Navigable String
    - BeautifulSoup
    - Comment
- Tag对象
    - 对应HTML中的标签
        - 用法: print(soup.tag_name)
                print(soup.tag_name.name)
                print(soup.tag_name.attrs)
        - 两个重要的属性
            - name: tag的名称
            - attrs: tag的属性,dict格式
    - 案例: 05--p08.py
- Navigable String对象
    - 对应内容值
    - 案例：05--p09.py
- BeautifulSoup对象
    - 表示的是一个文档的内容,一般可以把它当做tag对象
    - 一般用soup表示
- Comment对象
    - 特殊类型的Navigable String对象
    - 对其输出,不包括注释符号
### 遍历文档document对象
  - contents: tag的子节点以列表list的方式输出
  - children: 子节点以迭代器形式返回
  - descendants: 所有子孙类节点
  - string: 显示节点内容
  - 案例: 05--p10
### 搜索文档document对象
  - find_all(name, attrs, recursive, text, **kwargs)
        - name: 按那个字符串搜索,可传入内容为:
            - 字符串
            - 正则表达式
            - 列表
        - keyword: 表示属性
        - text: 对应tag的文本值
  - 案例: 05--p10.py
### CSS选择器
  - 使用soup.select,返回一个list
  - 通过标签名称: soup.select("title")
  - 通过类名: soup.select(".content")
  - 通过id: soup.select("#name_id")
  - 组合查找: soup.select("div #input_content")
  - 属性查找: soup.select("img[class="photo"]")
  - 获取tag内容: tag.tag_text
  - 案例: 05--p11.py
  